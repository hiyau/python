# -*- coding: utf-8 -*-
"""23-01-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dsqjJu8iVumeBlzvKW6yLNs8xV9vwQkX
"""

import pandas as pd
import numpy as np





df = pd.read_csv('/content/bbc_data.csv')

df['labels'].unique()

df['labels'].nunique()

df['data'].nunique()

df[['data','labels']].drop_duplicates()

df.isna().sum()

df['labels'].value_counts()

l = [1,2.,1,8,9]

df['data'] = df['data'].str.lower()

! pip install spacy

import spacy
nlp = spacy.load('en_core_web_sm')

df['data'] = df['data'].str.replace(',', ' ')
df['data'] = df['data'].str.replace('.', ' ')
df['data'] = df['data'].str.replace('-', ' ')
df['data'] = df['data'].str.replace('"', ' ')
df['data'] = df['data'].str.replace('  ',' ')

stop_words = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are',
              'aren', "aren't", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but',
               'by', 'can', 'couldn', "couldn't", 'd', 'did', 'didn', "didn't", 'do', 'does', 'doesn', "doesn't", 'doing',
               'don', "don't", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', "hadn't", 'has', 'hasn',
               "hasn't", 'have', 'haven', "haven't", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his',
               'how', 'i', 'if', 'in', 'into', 'is', 'isn', "isn't", 'it', "it's", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me',
               'mightn', "mightn't", 'more', 'most', 'mustn', "mustn't", 'my', 'myself', 'needn', "needn't", 'now', 'o', 'of',
               'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan',
               "shan't", 'she', "she's", 'should', "should've", 'shouldn', "shouldn't", 'so', 'some', 'such', 't', 'than', 'that',
               "that'll", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through',
               'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', "wasn't", 'we', 'were', 'weren', "weren't", 'what',
               'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', "won't", 'wouldn', "wouldn't", 'y',
               'you', "you'd", "you'll", "you're", "you've", 'your', 'yours', 'yourself', 'yourselves']

def stop_word_removal(text):
    tokens = text.split(' ')
    words_without_stopwords = [x for x in tokens if x not in stop_words]
    final_sentence = ' '.join(words_without_stopwords)
    return final_sentence

df['clean_data'] = df['data'].apply(stop_word_removal)

df

def get_embeddings(text):
    doc = nlp(text)
    return doc.vector

df["embeddings"] = df["clean_data"].apply(get_embeddings)

df

np.vstack(df["embeddings"].values).shape

print(f'{df["clean_data"][0]} \n\n\n {df["embeddings"][0]}')

df["embeddings"][0].shape

classes = df['labels'].unique()

classes

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
le.fit(classes)

df['Encoded_labels'] = le.transform(df['labels'])

df.tail()

pd.set_option('display.max_colwidth',300)

df[['Encoded_labels','labels']].drop_duplicates()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score


X = np.vstack(df["embeddings"].values)
y = df["Encoded_labels"]

# Create a model object
model = RandomForestClassifier(random_state=42)

from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=5)

# Print the cross-validation scores
print(scores)
print(f"Mean CV accuracy: {np.mean(scores)}")

from sklearn.tree import DecisionTreeClassifier
model2= DecisionTreeClassifier(criterion='gini', random_state=42)

scores = cross_val_score(model2, X, y, cv=5)
print(scores)
print(f"Mean CV accuracy: {np.mean(scores)}")

from sklearn.neighbors import KNeighborsClassifier
model3 = KNeighborsClassifier(n_neighbors=11,)

scores = cross_val_score(model3, X, y, cv=5)
print(scores)
print(f"Mean CV accuracy: {np.mean(scores)}")