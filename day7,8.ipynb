{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f8922-6c7c-45c1-bc2c-d6db692a0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "engine = pyttsx3.init()\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "def listen():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        speak(\"I am listening, please speak\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source)\n",
    "            command = recognizer.recognize_google(audio)\n",
    "            return command.lower()\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I did not catch that\")\n",
    "            return \"\"\n",
    "def main():\n",
    "    speak(\"Hello! I am your basic voice bot from Mallareddy College.\")\n",
    "    while True:\n",
    "        command = listen()\n",
    "        if \"hello\" in command:\n",
    "            speak(\"Hi there! Welcome to Mallareddy College.\")\n",
    "        elif \"what's your name\" in command or \"what is your name\" in command:\n",
    "            speak(\"My name is Basic Bot from Mallareddy College.\")\n",
    "        elif \"goodbye\" in command:\n",
    "            speak(\"Goodbye! Have a great day at Mallareddy College.\")\n",
    "        else:\n",
    "            speak(\"I didn't catch that. Please try again.\")\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f001137c-b8a4-4c6b-b0eb-d826cfb53fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hello\n",
      "You:  goodbye\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "def main():\n",
    "    speak(\"Hello! I am your simple bot from Mallareddy university\")\n",
    "    speak(\"You can say hello, ask my name, or say goodbye.\")\n",
    "    while True:\n",
    "        command=input(\"You: \").lower()\n",
    "        if \"hello\" in command:\n",
    "            speak(\"Hi there! welcome to Mallareddy college.\")\n",
    "        elif \"What's your name\" in command or \"What is your name\" in command:\n",
    "            speak(\"My name is simple but from Mallareddy college.\")\n",
    "        elif \"goodbye\" in command:\n",
    "            speak(\"Goodbye! Have a great day at mallareddy college\")\n",
    "            break\n",
    "        else:\n",
    "            speak(\"I didn't understand that. please try again.\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7575ee-822e-4610-8d89-66038994e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\hiya\\anaconda3\\lib\\site-packages (3.13.0)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\hiya\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\hiya\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hiya\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: comtypes in c:\\users\\hiya\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.9)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\hiya\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hiya\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition pyttsx3 pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3baa03-54c9-4faa-b19c-950f26024952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example text.The sentence.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "input_string = \"This is an example text.The sentence.\"\n",
    "all_sentences = tokenizer.tokenize(input_string)\n",
    "print(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73d7cef-72b2-474f-ad25-6f09531ea6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ello orld  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Hello, World ! 123\"\n",
    "text = re.sub(r'[^a-z\\s]','',text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4cf8e4d-8d59-484f-9246-4417f644e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.00      0.00      0.00         2\n",
      "        spam       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n",
      "prediction for new SMS: spam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Hiya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Hiya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Hiya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "data = [\n",
    "    ['spam','Had your mobie 11 months or more? U R entitled to Update to the latest'],\n",
    "    ['ham',\"I'm gone be home soon and I dont want to talk about this stuff\"],\n",
    "    ['spam','Congratulations! you have won a $1000 walmart gift card.call now'],\n",
    "    ['ham','Hey,are we still meeting for lunch tomorrow at 12? Let me know.'],\n",
    "    ['ham','Dont forget to bring the documents for the meeting'],\n",
    "    ['spam','You have been selected for a free vaction!Reply YES to claim now'],\n",
    "]\n",
    "labels = [row[0] for row in data]\n",
    "messages = [row[1] for row in data]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]','',text)\n",
    "    words = text.split()\n",
    "    from nltk.corpus import stopwords\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "preprocessed_messages = [preprocess_text(msg) for msg in messages]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_messages)\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y\n",
    ")\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test, y_pred))\n",
    "\n",
    "new_sms = \"Congatulations! you've won a free ticket to cghd\"\n",
    "new_sms_preprocessed = preprocess_text(new_sms)\n",
    "new_sms_vectorized = vectorizer.transform([new_sms_preprocessed])\n",
    "prediction = model.predict(new_sms_vectorized)\n",
    "print(f\"prediction for new SMS: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fb6ae-28c6-49ea-8b31-84afe766b4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}